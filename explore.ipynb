{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10fbe239",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import env\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as stats\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import MinMaxScaler, RobustScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "import wrangle as w\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b35ea5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = w.wrangle_zillow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dfb5cbb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, validate, test = w.split_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36426fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scaled, validate_scaled, test_scaled = w.scale_data(train, validate, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4a6063f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = train_scaled[['bedrooms','bathrooms', 'sq_feet']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0e0e271",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_vars = ['bedrooms','bathrooms', 'sq_feet']\n",
    "cluster_name = 'interior_cluster_k7'\n",
    "k_range = range(2,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "938f6196",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_k(X_train_scaled, cluster_vars, k_range):\n",
    "    sse = []\n",
    "    for k in k_range:\n",
    "        kmeans = KMeans(n_clusters=k)\n",
    "\n",
    "        # X[0] is our X_train dataframe..the first dataframe in the list of dataframes stored in X. \n",
    "        kmeans.fit(X_train_scaled[cluster_vars])\n",
    "\n",
    "        # inertia: Sum of squared distances of samples to their closest cluster center.\n",
    "        sse.append(kmeans.inertia_) \n",
    "\n",
    "    # compute the difference from one k to the next\n",
    "    delta = [round(sse[i] - sse[i+1],0) for i in range(len(sse)-1)]\n",
    "\n",
    "    # compute the percent difference from one k to the next\n",
    "    pct_delta = [round(((sse[i] - sse[i+1])/sse[i])*100, 1) for i in range(len(sse)-1)]\n",
    "\n",
    "    # create a dataframe with all of our metrics to compare them across values of k: SSE, delta, pct_delta\n",
    "    k_comparisons_df = pd.DataFrame(dict(k=k_range[0:-1], \n",
    "                             sse=sse[0:-1], \n",
    "                             delta=delta, \n",
    "                             pct_delta=pct_delta))\n",
    "\n",
    "    # plot k with inertia\n",
    "    plt.plot(k_comparisons_df.k, k_comparisons_df.sse, 'bx-')\n",
    "    plt.xlabel('k')\n",
    "    plt.ylabel('SSE')\n",
    "    plt.title('The Elbow Method to find the optimal k\\nFor which k values do we see large decreases in SSE?')\n",
    "    plt.show()\n",
    "\n",
    "    # plot k with pct_delta\n",
    "    plt.plot(k_comparisons_df.k, k_comparisons_df.pct_delta, 'bx-')\n",
    "    plt.xlabel('k')\n",
    "    plt.ylabel('Percent Change')\n",
    "    plt.title('For which k values are we seeing increased changes (%) in SSE?')\n",
    "    plt.show()\n",
    "\n",
    "    # plot k with delta\n",
    "    plt.plot(k_comparisons_df.k, k_comparisons_df.delta, 'bx-')\n",
    "    plt.xlabel('k')\n",
    "    plt.ylabel('Absolute Change in SSE')\n",
    "    plt.title('For which k values are we seeing increased changes (absolute) in SSE?')\n",
    "    plt.show()\n",
    "\n",
    "    return k_comparisons_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0991d5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_clusters(X_train_scaled, cluster_vars, k=7):\n",
    "    # create kmean object\n",
    "    kmeans = KMeans(n_clusters=k, random_state = 123)\n",
    "\n",
    "    # fit to train and assign cluster ids to observations\n",
    "    kmeans.fit(X_train_scaled[cluster_vars])\n",
    "\n",
    "    return kmeans\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a4165a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the centroids for each distinct cluster...\n",
    "\n",
    "def get_centroids(kmeans, cluster_vars, cluster_name):\n",
    "    # get the centroids for each distinct cluster...\n",
    "\n",
    "    centroid_col_names = ['centroid_' + i for i in cluster_vars]\n",
    "\n",
    "    centroid_df = pd.DataFrame(kmeans.cluster_centers_, \n",
    "                               columns=centroid_col_names).reset_index().rename(columns={'index': cluster_name})\n",
    "\n",
    "    return centroid_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3cbbf075",
   "metadata": {},
   "outputs": [],
   "source": [
    "# label cluster for each observation in X_train (X[0] in our X list of dataframes), \n",
    "# X_validate (X[1]), & X_test (X[2])\n",
    "\n",
    "def assign_clusters(df, kmeans, cluster_vars, cluster_name, centroid_df):\n",
    "    #for i in range(len(df)):\n",
    "        clusters = pd.DataFrame(kmeans.predict(df[cluster_vars]), \n",
    "                            columns=[cluster_name], index=df.index)\n",
    "\n",
    "        clusters_centroids = clusters.merge(centroid_df, on=cluster_name, copy=False).set_index(clusters.index.values)\n",
    "\n",
    "        df = pd.concat([df, clusters_centroids], axis=1)\n",
    "        return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "850c91b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_clusters():\n",
    "    \n",
    "    X_train_scaled = train_scaled[['bedrooms','bathrooms', 'sq_feet']]\n",
    "    X_train = train[['bedrooms','bathrooms', 'sq_feet']]\n",
    "    \n",
    "    cluster_vars = ['bedrooms','bathrooms', 'sq_feet']\n",
    "    cluster_name = 'interior_cluster_k7'\n",
    "    k_range = range(2,20)\n",
    "    \n",
    "    kmeans = create_clusters(X_train_scaled, cluster_vars, k=7)\n",
    "    \n",
    "    centroid_df = get_centroids(kmeans, cluster_vars, cluster_name)\n",
    "    \n",
    "    X = assign_clusters(X_train_scaled, kmeans, cluster_vars, cluster_name, centroid_df)\n",
    "    \n",
    "    dummy_df = pd.get_dummies(X['interior_cluster_k7'], dummy_na=False, drop_first=False)\n",
    "    \n",
    "    dummy_df = dummy_df.rename(columns={3:'is_cluster_3_k7'})\n",
    "    \n",
    "    X_train_scaled = pd.concat([X_train_scaled, dummy_df['is_cluster_3_k7']], axis=1)\n",
    "    X_train = pd.concat([X_train, dummy_df['is_cluster_3_k7']], axis=1)\n",
    "    \n",
    "    return X_train, X_train_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a08cf8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_validate_pred():\n",
    "    \n",
    "    X_validate_scaled = validate_scaled[['bedrooms','bathrooms','sq_feet']]\n",
    "    #X_train = train[['bedrooms','bathrooms', 'sq_feet']]\n",
    "    \n",
    "    #cluster_vars = ['bedrooms','bathrooms', 'sq_feet']\n",
    "    #cluster_name = 'interior_cluster_k7'\n",
    "    #k_range = range(2,20)\n",
    "    \n",
    "    #kmeans = create_clusters(X_train_scaled, 7, cluster_vars)\n",
    "    \n",
    "    #centroid_df = get_centroids(kmeans, cluster_vars, cluster_name)\n",
    "    \n",
    "    #X_train = assign_clusters(X_train, kmeans, cluster_vars, cluster_name, centroid_df)\n",
    "    \n",
    "    val_pred = pd.DataFrame(kmeans.predict(X_validate_scaled), index=X_validate_scaled.index)\n",
    "    \n",
    "    dummy_df_val = pd.get_dummies(val_pred[0], dummy_na=False, drop_first=False)\n",
    "    \n",
    "    #val_pred_dummies = pd.get_dummies(val_pred[0], dummy_na=False, drop_first=False)\n",
    "    \n",
    "    dummy_df_val = dummy_df_val.rename(columns={3:'is_cluster_3_k7'})\n",
    "    \n",
    "    X_validate_scaled = pd.concat([X_validate_scaled, dummy_df_val['is_cluster_3_k7']], axis=1)\n",
    "    #X_validate_scaled = X_validate_scaled.dropna()\n",
    "    #X_train = pd.concat([X_train, dummy_df['is_cluster_3_k7']], axis=1)\n",
    "    \n",
    "    return X_validate_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "086767dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_pred():\n",
    "    \n",
    "    X_test_scaled = test_scaled[['bedrooms','bathrooms','sq_feet']]\n",
    "    #X_train = train[['bedrooms','bathrooms', 'sq_feet']]\n",
    "    \n",
    "    #cluster_vars = ['bedrooms','bathrooms', 'sq_feet']\n",
    "    #cluster_name = 'interior_cluster_k7'\n",
    "    #k_range = range(2,20)\n",
    "    \n",
    "    #kmeans = create_clusters(X_train_scaled, 7, cluster_vars)\n",
    "    \n",
    "    #centroid_df = get_centroids(kmeans, cluster_vars, cluster_name)\n",
    "    \n",
    "    #X_train = assign_clusters(X_train, kmeans, cluster_vars, cluster_name, centroid_df)\n",
    "    \n",
    "    test_pred = pd.DataFrame(kmeans.predict(X_test_scaled), index=X_test_scaled.index)\n",
    "    \n",
    "    dummy_df_test = pd.get_dummies(test_pred[0], dummy_na=False, drop_first=False)\n",
    "    \n",
    "    #val_pred_dummies = pd.get_dummies(val_pred[0], dummy_na=False, drop_first=False)\n",
    "    \n",
    "    dummy_df_test = dummy_df_test.rename(columns={3:'is_cluster_3_k7'})\n",
    "    \n",
    "    X_test_scaled = pd.concat([X_test_scaled, dummy_df_test['is_cluster_3_k7']], axis=1)\n",
    "    #X_validate_scaled = X_validate_scaled.dropna()\n",
    "    #X_train = pd.concat([X_train, dummy_df['is_cluster_3_k7']], axis=1)\n",
    "    \n",
    "    return X_test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e62ec5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cluster_3_ttest():\n",
    "    \n",
    "    ttest_df = pd.concat([train.logerror, X_train_scaled.is_cluster_3_k7], axis=1)\n",
    "    \n",
    "    t, p = stats.ttest_1samp(ttest_df[ttest_df['is_cluster_3_k7'] == 1].logerror.abs(), ttest_df.logerror.abs().mean())\n",
    "    print(f't     = {t:.4f}')\n",
    "    print(f'p     = {p:.4f}')\n",
    "    #return t, pval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2ba750d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bed_log_corr():\n",
    "    \n",
    "    ttest_df = pd.concat([train.logerror, X_train_scaled.is_cluster_3_k7], axis=1)\n",
    "    \n",
    "    corr, p = stats.pearsonr(X_train_scaled.bedrooms, ttest_df.logerror)\n",
    "    print(f'corr  = {corr:.4f}')\n",
    "    print(f'p     = {p:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e58efe2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bath_log_corr():\n",
    "    \n",
    "    ttest_df = pd.concat([train.logerror, X_train_scaled.is_cluster_3_k7], axis=1)\n",
    "    \n",
    "    corr, p = stats.pearsonr(X_train_scaled.bathrooms, ttest_df.logerror)\n",
    "    print(f'corr  = {corr:.4f}')\n",
    "    print(f'p     = {p:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4543e277",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sq_feet_log_corr():\n",
    "    ttest_df = pd.concat([train.logerror, X_train_scaled.is_cluster_3_k7], axis=1)\n",
    "    \n",
    "    corr, p = stats.pearsonr(X_train_scaled.sq_feet, ttest_df.logerror)\n",
    "    print(f'corr  = {corr:.4f}')\n",
    "    print(f'p     = {p:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
