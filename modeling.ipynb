{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6e3cfea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from env import host, user, password\n",
    "\n",
    "import wrangle as w\n",
    "\n",
    "# Wrangling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Exploring\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score, explained_variance_score \n",
    "from math import sqrt\n",
    "\n",
    "# Visualizing\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Modeling\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62af5aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=w.wrangle_zillow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb4dcf0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, validate, test = w.split_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea4fd06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scaled, validate_scaled, test_scaled=w.scale_data(train, validate, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ebba7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled=train_scaled.drop(columns=['logerror'])\n",
    "y_train=train_scaled.logerror"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46517eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_validate_scaled=validate_scaled.drop(columns=['logerror'])\n",
    "y_validate=validate_scaled.logerror"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f12a7f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_scaled=test_scaled.drop(columns=['logerror'])\n",
    "y_test=test_scaled.logerror"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e10fa0",
   "metadata": {},
   "source": [
    "BASELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3fc6eb90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE using Mean\n",
      "Train/In-Sample:  0.03 \n",
      "Validate/Out-of-Sample:  0.03\n",
      "RMSE using Median\n",
      "Train/In-Sample:  0.03 \n",
      "Validate/Out-of-Sample:  0.03\n"
     ]
    }
   ],
   "source": [
    "# We need y_train and y_validate (and test) to be dataframes to append the new columns with predicted values. \n",
    "y_train = pd.DataFrame(y_train)\n",
    "y_validate = pd.DataFrame(y_validate)\n",
    "y_test = pd.DataFrame(y_test)\n",
    "\n",
    "# 1. Predict home_value_pred_mean\n",
    "logerror_pred_mean = y_train['logerror'].mean()\n",
    "y_train['logerror_pred_mean'] = logerror_pred_mean\n",
    "y_validate['logerror_pred_mean'] = logerror_pred_mean\n",
    "\n",
    "# 2. compute home_value_pred_median\n",
    "logerror_pred_median = y_train['logerror'].median()\n",
    "y_train['logerror_pred_median'] = logerror_pred_median\n",
    "y_validate['logerror_pred_median'] = logerror_pred_median\n",
    "\n",
    "# 3. RMSE of home_value_pred_mean\n",
    "rmse_train = mean_squared_error(y_train.logerror, y_train.logerror_pred_mean)**(1/2)\n",
    "rmse_validate = mean_squared_error(y_validate.logerror, y_validate.logerror_pred_mean)**(1/2)\n",
    "\n",
    "print(\"RMSE using Mean\\nTrain/In-Sample: \", round(rmse_train, 2), \n",
    "      \"\\nValidate/Out-of-Sample: \", round(rmse_validate, 2))\n",
    "\n",
    "# 4. RMSE of home_value_pred_median\n",
    "rmse_train = mean_squared_error(y_train.logerror, y_train.logerror_pred_median)**(1/2)\n",
    "rmse_validate = mean_squared_error(y_validate.logerror, y_validate.logerror_pred_median)**(1/2)\n",
    "\n",
    "print(\"RMSE using Median\\nTrain/In-Sample: \", round(rmse_train, 2), \n",
    "      \"\\nValidate/Out-of-Sample: \", round(rmse_validate, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64fa78c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the model object\n",
    "lm = LinearRegression(normalize=True)\n",
    "\n",
    "# fit the model to our training data. We must specify the column in y_train, \n",
    "# since we have converted it to a dataframe from a series! \n",
    "lm.fit(X_train_scaled, y_train.logerror)\n",
    "\n",
    "# predict train\n",
    "y_train['logerror_pred_lm'] = lm.predict(X_train_scaled)\n",
    "\n",
    "# evaluate: rmse\n",
    "rmse_train = mean_squared_error(y_train.logerror, y_train.logerror_pred_lm)**(1/2)\n",
    "\n",
    "# predict validate\n",
    "y_validate['logerror_pred_lm'] = lm.predict(X_validate_scaled)\n",
    "\n",
    "# evaluate: rmse\n",
    "rmse_validate = mean_squared_error(y_validate.logerror, y_validate.logerror_pred_lm)**(1/2)\n",
    "\n",
    "print(\"RMSE for OLS\\nTraining/In-Sample: \", rmse_train, \n",
    "      \"\\nValidation/Out-of-Sample: \", rmse_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7b2165",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "# make the polynomial features to get a new set of features\n",
    "pf = PolynomialFeatures(degree=2)\n",
    "\n",
    "# fit and transform X_train_scaled\n",
    "X_train_degree2 = pf.fit_transform(X_train_scaled)\n",
    "\n",
    "# transform X_validate_scaled & X_test_scaled\n",
    "X_validate_degree2 = pf.transform(X_validate_scaled)\n",
    "X_test_degree2 = pf.transform(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e900025",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the model object\n",
    "lm2 = LinearRegression(normalize=True)\n",
    "\n",
    "# fit the model to our training data. We must specify the column in y_train, \n",
    "# since we have converted it to a dataframe from a series! \n",
    "lm2.fit(X_train_degree2, y_train.logerror)\n",
    "\n",
    "# predict train\n",
    "y_train['logerror_pred_lm2'] = lm2.predict(X_train_degree2)\n",
    "\n",
    "# evaluate: rmse\n",
    "rmse_train = mean_squared_error(y_train.logerror, y_train.logerror_pred_lm2)**(1/2)\n",
    "\n",
    "# predict validate\n",
    "y_validate['logerror_pred_lm2'] = lm2.predict(X_validate_degree2)\n",
    "\n",
    "# evaluate: rmse\n",
    "rmse_validate = mean_squared_error(y_validate.logerror, y_validate.logerror_pred_lm2)**(1/2)\n",
    "\n",
    "print(\"RMSE for Poly 2\\nTraining/In-Sample: \", rmse_train, \n",
    "      \"\\nValidation/Out-of-Sample: \", rmse_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893143b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "# make the polynomial features to get a new set of features\n",
    "pf = PolynomialFeatures(degree=3)\n",
    "\n",
    "# fit and transform X_train_scaled\n",
    "X_train_degree3 = pf.fit_transform(X_train_scaled)\n",
    "\n",
    "# transform X_validate_scaled & X_test_scaled\n",
    "X_validate_degree3 = pf.transform(X_validate_scaled)\n",
    "X_test_degree3 = pf.transform(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921800e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the model object\n",
    "lm3 = LinearRegression(normalize=True)\n",
    "\n",
    "# fit the model to our training data. We must specify the column in y_train, \n",
    "# since we have converted it to a dataframe from a series! \n",
    "lm3.fit(X_train_degree3, y_train.logerror)\n",
    "\n",
    "# predict train\n",
    "y_train['logerror_pred_lm3'] = lm3.predict(X_train_degree3)\n",
    "\n",
    "# evaluate: rmse\n",
    "rmse_train = mean_squared_error(y_train.logerror, y_train.logerror_pred_lm3)**(1/2)\n",
    "\n",
    "# predict validate\n",
    "y_validate['logerror_pred_lm3'] = lm3.predict(X_validate_degree3)\n",
    "\n",
    "# evaluate: rmse\n",
    "rmse_validate = mean_squared_error(y_validate.logerror, y_validate.logerror_pred_lm3)**(1/2)\n",
    "\n",
    "# predict on test\n",
    "y_test['logerror_pred_lm3'] = lm3.predict(X_test_degree3)\n",
    "\n",
    "# evaluate: rmse\n",
    "rmse_test = mean_squared_error(y_test.logerror, y_test.logerror_pred_lm3)**(1/2)\n",
    "\n",
    "print(\"RMSE for Poly 3\\nTraining/In-Sample: \", rmse_train, \n",
    "      \"\\nValidation/Out-of-Sample: \", rmse_validate,\n",
    "      \"\\nTesting/Out-of-Sample Performance: \", rmse_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f1f6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the model object\n",
    "lars = LassoLars(alpha=1.0)\n",
    "\n",
    "# fit the model to our training data. We must specify the column in y_train, \n",
    "# since we have converted it to a dataframe from a series! \n",
    "lars.fit(X_train_scaled, y_train.logerror)\n",
    "\n",
    "# predict train\n",
    "y_train['logerror_pred_lars'] = lars.predict(X_train_scaled)\n",
    "\n",
    "# evaluate: rmse\n",
    "rmse_train = mean_squared_error(y_train.logerror, y_train.logerror_pred_lars)**(1/2)\n",
    "\n",
    "# predict validate\n",
    "y_validate['logerror_pred_lars'] = lars.predict(X_validate_scaled)\n",
    "\n",
    "# evaluate: rmse\n",
    "rmse_validate = mean_squared_error(y_validate.logerror, y_validate.logerror_pred_lars)**(1/2)\n",
    "\n",
    "print(\"RMSE for Lasso + Lars\\nTraining/In-Sample: \", rmse_train, \n",
    "      \"\\nValidation/Out-of-Sample: \", rmse_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5a60c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the model object\n",
    "glm = TweedieRegressor(power=0, alpha=1)\n",
    "\n",
    "# fit the model to our training data. We must specify the column in y_train, \n",
    "# since we have converted it to a dataframe from a series! \n",
    "glm.fit(X_train_scaled, y_train.logerror)\n",
    "\n",
    "# predict train\n",
    "y_train['logerror_pred_glm'] = glm.predict(X_train_scaled)\n",
    "\n",
    "# evaluate: rmse\n",
    "rmse_train = mean_squared_error(y_train.logerror, y_train.logerror_pred_glm)**(1/2)\n",
    "\n",
    "# predict validate\n",
    "y_validate['logerror_pred_glm'] = glm.predict(X_validate_scaled)\n",
    "\n",
    "# evaluate: rmse\n",
    "rmse_validate = mean_squared_error(y_validate.logerror, y_validate.logerror_pred_glm)**(1/2)\n",
    "\n",
    "print(\"RMSE for Tweedie\\nTraining/In-Sample: \", rmse_train, \n",
    "      \"\\nValidation/Out-of-Sample: \", rmse_validate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601f4234",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot to visualize actual vs predicted. \n",
    "plt.figure(figsize=(16,8))\n",
    "plt.hist(y_validate.logerror, color='red', alpha=.5, label=\"Actual Log Error\")\n",
    "plt.hist(y_validate.logerror_pred_lm3, color='blue', alpha=.5, label=\"Validate\")\n",
    "plt.hist(y_test.logerror_pred_lm3, color='green', alpha=.5, label='Test')\n",
    "plt.xlabel(\"Log Error\")\n",
    "plt.ylabel(\"Homes\")\n",
    "plt.title(\"Comparing the Distribution of Actual Log Error to Predicted w/Validate and w/Test\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63964d3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
